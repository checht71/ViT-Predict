{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a6ea7-15b0-4ff0-a309-592856fb4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './models/potholes-model-50epochs-FULL.pth'\n",
    "IMG_DIR = './images/'\n",
    "IMG_SIZE = (1090, 1920)\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7436b2-2797-4349-9af5-0f793e53a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTForImageClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdc241-a526-4419-a1ff-fbde05d08393",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ec80c-c6ef-4967-99c7-bed3114ea725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For loading the entire model\n",
    "model = torch.load(MODEL_PATH, map_location=device)\n",
    "model.eval() # Put the model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9437c-9640-40fb-8df5-ff14b061cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_path = listdir(IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f9165-9db3-4c44-93aa-423ac5bded8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predict(IMG_DIR, batch_path):\n",
    "    for batch in batch_path:\n",
    "        img = io.imread(IMG_DIR + batch)\n",
    "        transform = transforms.ToTensor()\n",
    "        resize = transforms.Resize((224,224))\n",
    "        input = resize(transform(img))\n",
    "        input = input.unsqueeze(0) #for batches of 1\n",
    "        print(input.shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input)\n",
    "            tensor_output = outputs.logits  # Assuming logits is the tensor containing the output values\n",
    "            _, preds = torch.max(tensor_output, 1)\n",
    "            print(preds)\n",
    "\n",
    "#batch_path = '20237-24_00648.jpg'\n",
    "convert_predict(IMG_DIR, batch_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
